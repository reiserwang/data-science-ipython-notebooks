{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "\n",
    "1. Before installing Keras, install one of its backend engines: [TensorFlow](https://www.tensorflow.org/install/), [Theano](http://deeplearning.net/software/theano/install.html#install), or [CNTK](https://docs.microsoft.com/en-us/cognitive-toolkit/setup-cntk-on-your-machine). Keras recommend the TensorFlow backend.\n",
    "\n",
    "    Optional dependencies:\n",
    "    * [cuDNN](https://docs.nvidia.com/deeplearning/sdk/cudnn-install/) (recommended if you plan on running Keras on GPU).\n",
    "    * HDF5 and [h5py](http://docs.h5py.org/en/latest/build.html) (required if you plan on saving Keras models to disk).\n",
    "    * [graphviz](https://graphviz.gitlab.io/download/) and [pydot](https://github.com/erocarrera/pydot) (used by [visualization utilities](https://keras.io/visualization/) to plot model graphs).\n",
    "\n",
    "2. **pip install keras**\n",
    "\n",
    "> You may need administrator privilage when installing keras package. In windows right click and select \"Run as administrator\".\n",
    "\n",
    "```sh\n",
    "pip install keras\n",
    "Collecting keras\n",
    "  Downloading https://files.pythonhosted.org/packages/68/12/4cabc5c01451eb3b413d19ea151f36e33026fc0efb932bf51bcaf54acbf5/Keras-2.2.0-py2.py3-none-any.whl (300kB)\n",
    "    100% |████████████████████████████████| 307kB 2.1MB/s\n",
    "Collecting pyyaml (from keras)\n",
    "  Downloading https://files.pythonhosted.org/packages/ad/d4/d895fb7ac1b0828151b829a32cefc8a8b58b4499570520b91af20982b880/PyYAML-3.13-cp35-cp35m-win_amd64.whl (205kB)\n",
    "    100% |████████████████████████████████| 215kB 2.7MB/s\n",
    "Collecting keras-applications==1.0.2 (from keras)\n",
    "  Downloading https://files.pythonhosted.org/packages/e2/60/c557075e586e968d7a9c314aa38c236b37cb3ee6b37e8d57152b1a5e0b47/Keras_Applications-1.0.2-py2.py3-none-any.whl (43kB)\n",
    "    100% |████████████████████████████████| 51kB 2.9MB/s\n",
    "Collecting keras-preprocessing==1.0.1 (from keras)\n",
    "  Downloading https://files.pythonhosted.org/packages/f8/33/275506afe1d96b221f66f95adba94d1b73f6b6087cfb6132a5655b6fe338/Keras_Preprocessing-1.0.1-py2.py3-none-any.whl\n",
    "Collecting scipy>=0.14 (from keras)\n",
    "  Downloading https://files.pythonhosted.org/packages/84/fc/f0adfaea340732ff25ccba17d1dd6fcc81fda302dbf31212ef7395463720/scipy-1.1.0-cp35-none-win_amd64.whl (31.1MB)\n",
    "    100% |████████████████████████████████| 31.1MB 259kB/s\n",
    "Collecting h5py (from keras)\n",
    "  Downloading https://files.pythonhosted.org/packages/d0/2c/4572e2e495341e667c89b490ad18ea71a5f9e9fafca06109a9c7db22848b/h5py-2.8.0-cp35-cp35m-win_amd64.whl (2.3MB)\n",
    "    100% |████████████████████████████████| 2.3MB 4.1MB/s\n",
    "Requirement already satisfied: six>=1.9.0 in c:\\users\\rewang\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages (from keras) (1.11.0)\n",
    "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\rewang\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages (from keras) (1.14.5)\n",
    "Installing collected packages: pyyaml, h5py, keras-applications, scipy, keras-preprocessing, keras\n",
    "Successfully installed h5py-2.8.0 keras-2.2.0 keras-applications-1.0.2 keras-preprocessing-1.0.1 pyyaml-3.13 scipy-1.1.0\n",
    "```\n",
    "\n",
    "Below is an example with the Keras Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 1060s 18ms/step - loss: 0.2696 - acc: 0.9166 - val_loss: 0.0683 - val_acc: 0.9792\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 1140s 19ms/step - loss: 0.0973 - acc: 0.9711 - val_loss: 0.0445 - val_acc: 0.9853\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 1091s 18ms/step - loss: 0.0777 - acc: 0.9772 - val_loss: 0.0400 - val_acc: 0.9870\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 1007s 17ms/step - loss: 0.0641 - acc: 0.9806 - val_loss: 0.0367 - val_acc: 0.9872\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 1031s 17ms/step - loss: 0.0557 - acc: 0.9829 - val_loss: 0.0395 - val_acc: 0.9878\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 1084s 18ms/step - loss: 0.0564 - acc: 0.9833 - val_loss: 0.0361 - val_acc: 0.9885\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 1208s 20ms/step - loss: 0.0496 - acc: 0.9855 - val_loss: 0.0347 - val_acc: 0.9897\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 1120s 19ms/step - loss: 0.0515 - acc: 0.9849 - val_loss: 0.0356 - val_acc: 0.9894\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 1012s 17ms/step - loss: 0.0474 - acc: 0.9863 - val_loss: 0.0389 - val_acc: 0.9888\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 1124s 19ms/step - loss: 0.0470 - acc: 0.9861 - val_loss: 0.0393 - val_acc: 0.9898\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 1027s 17ms/step - loss: 0.0472 - acc: 0.9870 - val_loss: 0.0384 - val_acc: 0.9891\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 1038s 17ms/step - loss: 0.0493 - acc: 0.9863 - val_loss: 0.0438 - val_acc: 0.9880\n",
      "Test loss: 0.04383922001640435\n",
      "Test accuracy: 0.988\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py\n",
    "\n",
    "Trains a simple convnet on the MNIST dataset.\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "16 seconds per epoch on a GRID K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFMzMLONQMDOzjEPBzMwy/wmwX7BFl4QZvgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21bdb7097b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss=[0.2696,0.0973,0.0777,0.0641,0.0557,0.0564,0.0496,0.0515,0.0474,0.0470, 0.0472, 0.0493]\n",
    "accarucy=[0.9166,0.9711,0.9772,0.9806,0.9829,0.9833,0.9855,0.9849,0.9863,0.9861, 0.9870, 0.9863]\n",
    "\n",
    "plt.plot(loss)\n",
    "plt.plot(accarucy)\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##  How can we possibly improve the performance?\n",
    "\n",
    "###   Multi-thread\n",
    "\n",
    "Keras is thread safe, if you pay a little attention to it.\n",
    "\n",
    "In **reinforcement learning** there is an algorithm called **[Asynchronous Advantage Actor Critics (A3C)](https://arxiv.org/pdf/1602.01783.pdf)** where each agent relies on the same neural network to tell them what they should do in a given state. In other words, each thread calls model.predict concurrently as in your problem. An example implementation with Keras of it is here.\n",
    "\n",
    "You should, however, pay extra attention to this line if you looked into the code: \n",
    "\n",
    "```\n",
    "model._make_predict_function() # have to initialize before threading\n",
    "```\n",
    "\n",
    "This is never mentioned in the Keras docs, but its necessary to make it work concurrently. In short, _make_predict_function is a function that compiles the predict function. In multi thread setting, you have to manually call this function to compile predict in advance, otherwise the predict function will not be compiled until you run it the first time, which will be problematic when many threading calling it at once. A detailed explanation [here](https://github.com/keras-team/keras/issues/6124).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
